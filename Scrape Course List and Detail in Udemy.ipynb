{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Course List and Detail in Udemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I built open-source python packages to scrape courses from Udemy website with BeautifulSoup. Udemy is an online education plateform which provides courses from diverse industries. These packages will help people who are interested in finding the course list for a particular industry or course details for a particular course name.\n",
    "\n",
    "* ScrapeMultiplePageinCategory(category, num_of_page): it will return all the course details in the top k pages in that category\n",
    "* ScrapeDetailofClass(course_name): it will return the course detail for the particular course we are looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "from lxml import html\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know the parent and children relationship between the categories and subcategories by returning a list of the relationship. Firstly, we want to map the categories with ID and sub_category. One thing to note is that we won't find any ID information in the Udemy website but the ID is used to link the category, sub_category_level1 and sub_category_level2 in the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.udemy.com/'\n",
    "h = html.fromstring(requests.get(url).text)\n",
    "\n",
    "\n",
    "def CategorytoSubcatgory1(url, h):\n",
    "    # create a dictionary {data_id_level1, {category, sub_category_level1}}\n",
    "    id_level1_ctgy = {}\n",
    "    course_path = h.xpath('//a[contains(@class, \"cat js-subc\")]/@href')\n",
    "    print(course_path[0])\n",
    "    data_id = h.xpath('//a[contains(@class, \"cat js-subc\")]/@data-id')\n",
    "\n",
    "    k = 0\n",
    "    while k < len(data_id):\n",
    "        # we find the category and sub_category_level1 by using the name in the website URL\n",
    "        path = course_path[k][9:-1]\n",
    "        data_id_level1 = data_id[k]\n",
    "\n",
    "        for i, j in enumerate(path):\n",
    "            if j == '/':\n",
    "                category = path[:i]\n",
    "                sub_category_level1 = path[i + 1:]\n",
    "                if '-' in category:\n",
    "                    category_update = category.replace('-', ' ')\n",
    "                else:\n",
    "                    category_update = category\n",
    "                if '-' in sub_category_level1:\n",
    "                    sub_category_level1_update = sub_category_level1.replace('-', ' ')\n",
    "                else:\n",
    "                    sub_category_level1_update = sub_category_level1\n",
    "                id_level1_ctgy[data_id_level1] = {category_update: sub_category_level1_update}\n",
    "\n",
    "        k += 1\n",
    "    return id_level1_ctgy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the relationship between category and subcategory_level1, we want to map the subcategory_level1 to subcategory_level2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape all the subcategory_level_2 titles\n",
    "def Subcategory2(url, h): \n",
    "    #                                 subCategory_map2      subCategory_map1\n",
    "    # create a dictionary {category, {sub_category_level1, {sub_category_level2, data_id_level2}}}\n",
    "    subCtgy2 = {}\n",
    "    data_id_level2s = h.xpath('//a[contains(@href, \"topic\")]/@data-id')\n",
    "    sub_ctgy_level2 = h.xpath('//a[contains(@href, \"topic\")]/@href')\n",
    "    j = 0\n",
    "    while j < len(data_id_level2s):\n",
    "        temp = sub_ctgy_level2[j][7:-1]\n",
    "#         if '-' in temp:\n",
    "#             sub_ctgy_level2_update = temp.replace('-', ' ')\n",
    "#         else:\n",
    "#             sub_ctgy_level2_update = temp\n",
    "        subCtgy2[data_id_level2s[j]] = temp\n",
    "        j += 1\n",
    "    return subCtgy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the relationship between subcategory_level1 and subcategory_level2\n",
    "def Subcategory1toSubcategory2(url, h):\n",
    "    subctgy1_subCtgy2 = {}\n",
    "    divs = h.xpath('//div[contains(@class, \"js-side-nav-popular-topics\")]')\n",
    "    data_connect = h.xpath('//div[contains(@class, \"js-side-nav-popular-topics\")]/@data-id')\n",
    "\n",
    "    for i in range(len(divs)):\n",
    "        ind_list = divs[i].xpath('a')\n",
    "        id_subCtgy2 = {}\n",
    "        id_list = divs[i].xpath('a/@data-id')\n",
    "        for k in range(len(ind_list)):\n",
    "            subctgy_list = ind_list[k].text\n",
    "            id_subCtgy2[id_list[k]] = subctgy_list\n",
    "        subctgy1_subCtgy2[data_connect[i]] = id_subCtgy2\n",
    "    return subctgy1_subCtgy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the parent-children relationship of categories and subcategories, we want to find the class details in the category. The details of each class contains the information including name, url, instructor, rating and price in the top k pages. We can choose the number of pages we like and if the num_of_page is not entered, we will return the courses detail in the first five pages.\n",
    "\n",
    "We can use selenium chrome driver to scrape the course details because the beautiful soup only scrapes the courses on the current screen. We need to control the mouse to scroll down, so we can get all the courses in the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELENIUM_CHROME_DRIVER_PATH = '/Users/jiongjiangduan/Documents/chromedriver'\n",
    "SELENIUM_CUSTOM_CHROME_PATH = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "SCROLL_PAUSE_TIME = 1.75\n",
    "SCROLL_PAGE_SIZE = 600\n",
    "\n",
    "def ScrapeMultiplePageinCategory(category, num_of_page):\n",
    "    if num_of_page == 0:\n",
    "        first_k_page = 5\n",
    "    else:\n",
    "        first_k_page = num_of_page\n",
    "        \n",
    "    category.lower()\n",
    "    for i in category:\n",
    "        if ' ' in category:\n",
    "            temp = category.replace(' ', '-')\n",
    "            \n",
    "    k = 1\n",
    "    for k <= first_k_page:\n",
    "        url = \"https://www.udemy.com/topic/\" + temp + \"?p=\" + k\n",
    "        ScrapePageinCategory(url)\n",
    "\n",
    "def ScrapePageinCategory(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.binary_location = SELENIUM_CUSTOM_CHROME_PATH\n",
    "\n",
    "    browser = webdriver.Chrome(SELENIUM_CHROME_DRIVER_PATH, options=options)\n",
    "    browser.get(url)\n",
    "\n",
    "    # scrape the course link in the Udemy website\n",
    "    urls = list()\n",
    "    scroll(browser)\n",
    "\n",
    "    html = browser.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    main_content = soup.find(\"div\", \"main-content\")\n",
    "    containers = main_content.find_all(\"div\", {\"class\": \"popover--popover--t3rNO popover--popover-hover--14ngr\"})\n",
    "    for div_tag in containers:\n",
    "        a_tag = div_tag.find_all(\"a\")\n",
    "        for website_link in a_tag:\n",
    "            if website_link['href'] is not None:\n",
    "                urls.append(\"https://www.udemy.com\"+website_link['href'])\n",
    "\n",
    "    # scrape the course title in the Udemy website\n",
    "    titles_content = main_content.find_all(\"div\", {\"class\":\"udlite-heading-sm udlite-focus-visible-target course-card--course-title--2f7tE\"})\n",
    "    for title in titles_content:\n",
    "        if title is not None:\n",
    "            print(title.text)\n",
    "\n",
    "    # scrape the instructor in the Udemy website\n",
    "    instructor_content = main_content.find_all(\"div\", {\"class\":\"udlite-text-xs course-card--instructor-list--lIA4f\",\n",
    "                                                       \"data-purpose\":\"safely-set-inner-html:course-card:visible-instructors\"})\n",
    "    for instructor in instructor_content:\n",
    "        if instructor is not None:\n",
    "            print(instructor.text)\n",
    "\n",
    "    # scrape the rating of each course\n",
    "    rating_content = main_content.find_all(\"span\", {\"class\":\"udlite-heading-sm star-rating--rating-number--3lVe8\"})\n",
    "    for rating in rating_content:\n",
    "        if rating is not None:\n",
    "            print(rating.text)\n",
    "    browser.close()\n",
    "\n",
    "    print(\"Total Nums: \" + str(len(urls)))\n",
    "    print(*urls, sep=\"\\n\")\n",
    "\n",
    "\n",
    "def scroll(browser):\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    print(\"Page Height: \" + str(last_height))\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        next_height = last_height + SCROLL_PAGE_SIZE\n",
    "        browser.execute_script(\"window.scrollTo(0, \" + str(next_height) + \");\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height < last_height:\n",
    "            break\n",
    "        last_height = next_height\n",
    "        print(\"Page Height: \" + str(last_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can have a look of a particular class. We can get the detail of a course if we know the class name instead of the class category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/',\n",
       " 'Learn Python for Data Science, Structures, Algorithms, Interviews | Udemy',\n",
       " 'Jose Portilla',\n",
       " 'Current price$14.99Original Price$109.99Discount86% off',\n",
       " 'Rating: 4.6 out of 54.6 (85,526 ratings)',\n",
       " '381,085 student']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ScrapeDetailofClass(course_name):\n",
    "    ans = []\n",
    "    course_name.lower()\n",
    "    for i in course_name:\n",
    "        if ' ' in course_name:\n",
    "            temp = course_name.replace(' ', '-')\n",
    "        else:\n",
    "            temp = course_name\n",
    "    url = 'https://www.udemy.com/course/' + temp + '/'\n",
    "    result = requests.get(url)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    \n",
    "    # url\n",
    "    course_url = url\n",
    "    ans.append(course_url)\n",
    "    \n",
    "    # course title\n",
    "    title = soup.find('title')\n",
    "    ans.append(title.text)\n",
    "    \n",
    "    # The instructor\n",
    "    instructor_info = soup.find_all(\"a\", {\"class\": \"udlite-btn udlite-btn-large udlite-btn-link udlite-heading-md udlite-text-sm udlite-instructor-links\", \n",
    "                                          \"data-position\":\"1\",\n",
    "                                          \"href\":\"#instructor-1\"})\n",
    "    for instructor_name in instructor_info:\n",
    "        if instructor_name is not None:\n",
    "            ans.append(instructor_name.text)\n",
    "    \n",
    "    # course price\n",
    "    price_info = soup.find_all(\"div\",{\"class\": \"price-text--container--Ws-fP udlite-clp-price-text\"})\n",
    "    for price in price_info:\n",
    "        if price is not None:\n",
    "            ans.append(price.text)\n",
    "    \n",
    "    # The course rating\n",
    "    rating_info = soup.find_all(\"div\", {\"class\": \"ud-component--course-landing-page-udlite--rating\"})\n",
    "    for score in rating_info:\n",
    "        if score is not None:\n",
    "            ans.append(score.text)\n",
    "    \n",
    "    # The number of student enrolled in the course\n",
    "    num_of_enrollment = soup.find_all(\"div\", {\"data-purpose\":\"enrollment\"})\n",
    "    for enrollment in num_of_enrollment:\n",
    "        if enrollment is not None:\n",
    "            ans.append(enrollment.text[1:-2])\n",
    "    \n",
    "    if len(ans) == 1:\n",
    "        raise Exception('Please Enter Another Course Name')\n",
    "        \n",
    "    return ans\n",
    "\n",
    "\n",
    "ScrapeDetailofClass('python for data science and machine learning bootcamp')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
